{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fast_Style_NST.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ajraymond27/entertAIn/blob/master/Fast_Style_NST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cswKy-6zg-zk"
      },
      "source": [
        "# **Fast NeuralStyleTransfer Model**\n",
        "---\n",
        "This notebook is for D.ai TRIP MEDIA use only. If you are accessing this notebook and wish to try it out, please make a copy in your personal Drive to work from. Thanks! \n",
        "---\n",
        "---\n",
        "About this notebook:\n",
        "---\n",
        "---\n",
        "Neural style transfer is an optimization technique used to take two images—a content image and a style reference image (such as an artwork by a famous painter)—and blend them together so the output image looks like the content image, but “painted” in the style of the style reference image.\n",
        "\n",
        "This is implemented by optimizing the output image to match the content statistics of the content image and the style statistics of the style reference image. These statistics are extracted from the images using a convolutional network.\n",
        "\n",
        "For example, let’s take an image of this dog and Wassily Kandinsky's Composition 7:\n",
        "\n",
        "<img src=\"https://storage.googleapis.com/download.tensorflow.org/example_images/YellowLabradorLooking_new.jpg\" width=\"500px\"/>\n",
        "\n",
        "<img src=\"https://storage.googleapis.com/download.tensorflow.org/example_images/Vassily_Kandinsky%2C_1913_-_Composition_7.jpg\" width=\"500px\"/>\n",
        "\n",
        "Now how would it look like if Kandinsky decided to paint the picture of this Dog exclusively with this style? Something like this?\n",
        "\n",
        "<img src=\"https://tensorflow.org/tutorials/generative/images/stylized-image.png\" style=\"width: 500px;\"/>\n",
        "\n",
        "\n",
        "---\n",
        "Start Creating! \n",
        "---\n",
        "---\n",
        "As you use this notebook, keep giving AJ feedback & ideas on how to make this process easier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCiGImELD4uF"
      },
      "source": [
        "# **Enabling and Testing GPU**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPtvvu3lDvIA",
        "cellView": "form"
      },
      "source": [
        "#@title Hit This GPU Bruh\n",
        "#Check if GPU is connected\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))\n",
        "\n",
        "# How much GPU, tho?\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)\n",
        "\n",
        "# What about RAM?\n",
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uraJMNB-82LT"
      },
      "source": [
        "# Preprocess Video"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVXnDRSW9Bmd",
        "cellView": "form"
      },
      "source": [
        "#@title Import Media & Convert Video To Image Sequence\n",
        "\n",
        "#@markdown - In the left sidebar, click the Files tab\n",
        "\n",
        "#@markdown - Create a folder named anything you'd like\n",
        "\n",
        "#@markdown - Within that folder, create two more named 'content' and 'style'\n",
        "\n",
        "#@markdown - Drag & drop your style image in your style folder and your video into the folder you named. Leave the content folder empty\n",
        "\n",
        "#@markdown - Right click your video file and choose 'Copy path'. Paste your video path into the 'video_directory' input field below:\n",
        "video_path = '' #@param {type:\"string\"}\n",
        "\n",
        "#@markdown - Right click your content folder and choose 'Copy path'. Paste your folder path into the 'content_directory' input field below:\n",
        "content_path = '' #@param {type:\"string\"}\n",
        "\n",
        "#@markdown - Right click your style image and choose 'Copy path'. Paste your folder path into the 'content_directory' input field below:\n",
        "style_path = '' #@param {type:\"string\"}\n",
        "\n",
        "#@markdown - Enter how many frames per second you want to capture:\n",
        "fps =  30#@param {type:\"number\"}\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "vidcap = cv2.VideoCapture(video_path)\n",
        "os.chdir(content_path)\n",
        "\n",
        "\n",
        "def getFrame(sec):\n",
        "    vidcap.set(cv2.CAP_PROP_POS_MSEC,sec*1000)\n",
        "    hasFrames,image = vidcap.read()\n",
        "    if hasFrames:\n",
        "      if count < 10:\n",
        "        cv2.imwrite(\"image_00\"+str(count)+\".PNG\", image)     # save frame as JPG file\n",
        "      elif count < 100:\n",
        "        cv2.imwrite(\"image_0\"+str(count)+\".PNG\", image)     # save frame as JPG file\n",
        "      else:\n",
        "        cv2.imwrite(\"image_\"+str(count)+\".PNG\", image)     # save frame as JPG file\n",
        "    return hasFrames\n",
        "sec = 0\n",
        "frameRate = 1/fps #//it will capture image in each 0.5 second\n",
        "count=0\n",
        "success = getFrame(sec)\n",
        "while success:\n",
        "    count = count + 1\n",
        "    sec = sec + frameRate\n",
        "    sec = round(sec, 2)\n",
        "    success = getFrame(sec)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTA9YBBID-Jz"
      },
      "source": [
        "# **Import & Configure Libraries & Models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uU4--JBGD9f4",
        "cellView": "form"
      },
      "source": [
        "#@title Art Vandalay, Importer / Exporter\n",
        "import os\n",
        "from os.path import exists\n",
        "# Load compressed models from tensorflow_hub\n",
        "os.environ['TFHUB_MODEL_LOAD_FORMAT'] = 'COMPRESSED'\n",
        "tf.__version__\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import IPython.display as display\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "mpl.rcParams['figure.figsize'] = (12, 12)\n",
        "mpl.rcParams['axes.grid'] = False\n",
        "\n",
        "import numpy as np\n",
        "import PIL.Image\n",
        "import time\n",
        "import functools\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aoc59U8jEIPr"
      },
      "source": [
        "# **Set Path to Content and Style Images**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smzt3v9yEJmD",
        "cellView": "form"
      },
      "source": [
        "#@title Download Google\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "from google.colab import files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Ox0Z_9ZELhd",
        "cellView": "form"
      },
      "source": [
        "#@title Authenticate Yourself\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vw26fStDEPhg",
        "cellView": "form"
      },
      "source": [
        "#@title Connect to Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vzb89Q-1oape",
        "cellView": "form"
      },
      "source": [
        "#@title Set Batch Size\n",
        "#@markdown ---\n",
        "first_image =  0#@param {type:\"integer\"}\n",
        "last_image =  100#@param {type:\"integer\"}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cy8N3yCfFkZM",
        "cellView": "form"
      },
      "source": [
        "#@title Enter your desired output resolution\n",
        "#@markdown ---\n",
        "#@markdown Value should be width if in landscape orientation\n",
        "\n",
        "#@markdown Value should be hight if in portrait orientation\n",
        "\n",
        "#@markdown Example: 1920x1080px ... Value = 1920\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "max_dimension =  1920#@param {type:\"integer\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNfim1UxEVFy",
        "cellView": "form"
      },
      "source": [
        "#@title Download all content and style images\n",
        "\n",
        "def tensor_to_image(tensor):\n",
        "  tensor = tensor*255\n",
        "  tensor = np.array(tensor, dtype=np.uint8)\n",
        "  if np.ndim(tensor)>3:\n",
        "    assert tensor.shape[0] == 1\n",
        "    tensor = tensor[0]\n",
        "  return PIL.Image.fromarray(tensor)\n",
        "\n",
        "def load_img(path_to_img):\n",
        "  max_dim = max_dimension\n",
        "  img = tf.io.read_file(path_to_img)\n",
        "  img = tf.image.decode_image(img, channels=3)\n",
        "  img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "\n",
        "  shape = tf.cast(tf.shape(img)[:-1], tf.float32)\n",
        "  long_dim = max(shape)\n",
        "  scale = max_dim / long_dim\n",
        "\n",
        "  new_shape = tf.cast(shape * scale, tf.int32)\n",
        "\n",
        "  img = tf.image.resize(img, new_shape)\n",
        "  img = img[tf.newaxis, :]\n",
        "  return img\n",
        "\n",
        "def imshow(image, title=None):\n",
        "  if len(image.shape) > 3:\n",
        "    image = tf.squeeze(image, axis=0)\n",
        "\n",
        "  plt.imshow(image)\n",
        "  if title:\n",
        "    plt.title(title)\n",
        "\n",
        "content_images = []\n",
        "image_paths = sorted(os.listdir(content_path))\n",
        "\n",
        "# iterate through the names of contents of the folder\n",
        "for image_path in image_paths[first_image:last_image]:\n",
        "\n",
        "  # create the full input path and read the file\n",
        "  # input_path = os.path.join(content_path, image_path)\n",
        "  content_image = load_img(image_path)\n",
        "\n",
        "  content_images.append(content_image)\n",
        "\n",
        "\n",
        "style_image = load_img(style_path)\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "imshow(content_images[0], 'Content Image')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "imshow(style_image, 'Style Image')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVFwom_KEngP"
      },
      "source": [
        "# Fast Style Transfer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jeBz1tp1En-t",
        "cellView": "form"
      },
      "source": [
        "#@title Run Fast Style Transfer\n",
        "import tensorflow_hub as hub\n",
        "hub_model = hub.load('https://tfhub.dev/google/magenta/arbitrary-image-stylization-v1-256/2')\n",
        "\n",
        "fast_styled_images = []\n",
        "start = time.time()\n",
        "\n",
        "for i in content_images:\n",
        "  stylized_image = hub_model(tf.constant(i), tf.constant(style_image))[0]\n",
        "  tensor_to_image(stylized_image)\n",
        "  fast_styled_images.append(stylized_image)\n",
        "\n",
        "end = time.time()\n",
        "print(\"Total time: {:.1f}\".format(end-start))\n",
        "print(\"Number of Styled Frames: {}\".format(len(fast_styled_images)))\n",
        "print(\"Example:\")\n",
        "tensor_to_image(fast_styled_images[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4o8dgWZXE1tV"
      },
      "source": [
        "# Save Styled Images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUIRrtg4ZBaQ",
        "cellView": "form"
      },
      "source": [
        "#@title Save output to company drive folder\n",
        "\n",
        "#@markdown Within your drive folder, create an output folder. Right click the folder and choose 'Copy path'. Paste your output path in the input field below:\n",
        "output_path = '' #@param {type:\"string\"}\n",
        "\n",
        "import os\n",
        "os.chdir(output_path)\n",
        "!pwd\n",
        "\n",
        "count = first_image\n",
        "\n",
        "for i in fast_styled_images:\n",
        "  file_name = 'fast-styled-image-' + str(count) + \".png\"\n",
        "  tensor_to_image(i).save(file_name)\n",
        "  files.download(file_name)\n",
        "  count += 1"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}